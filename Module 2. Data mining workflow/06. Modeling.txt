1: Classification problem:
##Supervised learning.
First, there must be a batch of data that already has label results.
If there is a lack of known information: 1. Consider using other algorithms, such as clustering algorithms; 2. Consider processing data, such as manual annotation.

a. Two classification problem:
The only questions to answer are yes or no
B. Multi-classification problem:
Expand the optional range of labels based on the two categories;
C. Multi-label classification:
A piece of data under multi-label classification can be labeled with multiple labels

Common algorithms such as: KNN. Decision tree. Random forest, SVM
They are all designed to solve classification problems.

2: Clustering problem:
##Clustering is unsupervised learning.
There are tens of millions of users on an APP, and users must be divided into several groups.
##Clustering is the process of dividing a data set into multiple groups. It processes known data and does not involve location data.
Common relationships include: mutual exclusion, intersection, hierarchy, fuzzy (using probability to express relationships (0.5, 0.5, 0.7), etc.)
a. Clustering based on partitioning, usually used for mutually exclusive groups;
B. Density-based clustering is used to solve the problem of uneven shapes;
C. Hierarchical clustering, suitable for data segmentation
D. model-based clustering

Three: Regression problem:
##The classification method outputs discrete labels; the regression method outputs continuous labels.
(The goal is that the loss of all data points to the line is minimal)
Can be segmented based on regression methods (e.g. above and below house prices)

Four: Related issues
## Unsupervised learning. The goal is to discover and exploit correlation patterns hidden in the data.
##Widely used in product sales, system recommendations, user behavior analysis, etc. Practical knowledge verification is required when applying.

Finally, there are three ways of model integration:
1. Bagging: input data into multiple models, and then output the results after making the decision (random forest similar method)
2. Boosting: A serial algorithm that uses the result as a feature to continuously strengthen the learning effect.
3. Stacking: perform horizontal expansion and traversal enhancement. We must continue to try and optimize our business.
一：分类问题：
##有监督学习。
首先要有一批已经有标签结果的数据
如果缺少已知信息：1. 考虑使用其他算法，如聚类算法；2. 考虑处理数据，如人工进行标注法

a. 二分类问题：
要回答的问题只有是或者否
B. 多分类问题：
在二分类的基础上将标签的可选范围扩大；
C。多标签分类：
多标签分类下的一条数据可以被标注上多个标签

常见算法如：KNN. 决策树. 随机森林、SVM
都是为了解决分类问题设计的。

二： 聚类问题：
##聚类是无监督学习。
在一个APP上有千万用户，要把用户分为若干组。
##聚类是把一个数据集划分为多个组的过程，是对已知数据进行处理，不涉及位置数据。
常见的关系有：互斥、相交、层次、模糊（用概率表示关系（0.5, 0.5, 0.7）之类的）
a. 基于划分的聚类，通常用于互斥的小组；
B. 基于密度的聚类，用于解决形状不均匀的情况；
C。 层次的聚类，适合数据细分的情况
D。基于模型的聚类

三： 回归问题：
##分类方法输出的是离散的标签；回归方法输出的结果是连续的
（目的是所有数据点到线的损失是最小的）
可以根据回归方法进行分段（如高于和低于房价）

四： 关联问题
## 无监督学习。目标是挖掘隐藏在数据中的关联模式并加以利用。
##广泛用于商品销售、系统推荐、用户行为分析等。在应用时需要实际知识校验。

最后是模型集成三种方式：
1. Bagging（装袋法）：输入数据到多个模型，然后得出结果决策后，输出结果（随机森林相似方法）
2. Boosting（增强法）：串行算法，将结果作为一个特征，不断强化学习的效果。
3. Stacking（堆叠法）：进行横向扩展和穿行增强。要在业务上不断进行尝试和优化。
