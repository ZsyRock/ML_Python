如何评估模型是否已经达标？常用的评估指标：
1. 准确率相关指标-（如800只是猪，200只不是，可以画一个混淆矩阵出来）可以直接反应一个模型对于样本数据的学习情况。是一种标准化的检验。
高阳性（true positive TP）
真阴性（TN）
假阳性（FP）
假阴性（FN）
准确率Accuracy：（TP+TN）/(TP+FP+FN+TN)
精确率（precision）：预测TP的结果占所有P的概率：TP/(TP+FP)
召回率（Recall）:预测TP的结果占所有实际T的概率：TP/(TP+FN)

ROC和AUC：（选多少概率值来判定结果）
指定”是“的概率为0.1以上时为”是“
”是“的概率为0.1以下为”否“
以此得出多组混淆矩阵。

那么每一组混淆矩阵都有：
真正例率：TP/(TP+FN)
假正例率：FP/(FP+TN)
使用这两个值在坐标系中描点：
y = TP/(TP+FN)
x = FP/(FP+TN)
即可得出ROC曲线，曲线下的面积为AUC值。可以反应一个模型的稳定性。当ROC接近对角线时，说明模型很不稳定。

2. 业务抽样评估
由于建模过程难免有错误产生，模型是基于业务指定的，进行抽样评估可以减弱这种情况
3. 泛化能力评估
##模型对与未知任务的判断能力
可以通过overfitting和underfitting来判断。
一个是学死了（只要和样本不同就不对），一个是没学会（特征学习不完全）
此时需要对数据进行重新整理，总结出过拟合和欠拟合的原因，然后调整数据重新进行训练。

其他评估指标：
1. 模型速度（开销）
2. 鲁棒性：错误数据是否会导致模型崩溃
3. 可解释性：在很多场景下（比如金融风控），需要给出一个让人信服的理由


评估数据的处理：
随机抽样：分成训练集和测试机，使用测试机对模型进行测试，得到各种准确率指标
随即多次抽样：抽样得到N组测试机，使用N组的测试机的平均值作为最终结果
交叉验证：同05的交叉验证法：先把数据集划分为N个，每次使用N-1个数据集训练，剩下的作为测试集。以此进行N次训练。
自助法：同05自助法：小数据集时，通过重复抽样构建数据集。随机有放回抽取样本构建训练集，训练K个模型结果作为这个题获得的准确率
