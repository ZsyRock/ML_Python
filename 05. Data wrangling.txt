Preparing your data: How to process it for completeness. Clean data?

1. You need to know what data is required for which project and where to obtain it. Even if the company has a data department, it is still necessary to master the skills of using the database. For example, the relational database MuSQL requires communication and negotiation with various business departments to obtain data.

two. Data exploration (increasing data/enhancing data dimensionality)
More data:
a. Split the content into words and obtain a segmented field;
b. Perform word statistics on the content after the division to see which word appears the most;
C. Segment the title into words and perform word statistics
D. You can mark the part-of-speech of words and obtain a part-of-speech data;
E. You can look for some special words, such as the name of a celebrity or the name of an organization. The name of the location and other information; if it is numerical data, it can be expanded by calculating the mean, variance, median, standard deviation, and maximum and minimum values.

Three: Data cleaning (reduce data)
a. Missing value processing. The reasons for missing data and the impact of missing data need to be analyzed. Generally there are three methods: delete, complete, ignore
B. Outliers. Error conditions/normal conditions. The processing methods are: incorrect data - correct/discard; correct data - process according to business needs, and retain/correct according to abnormal conditions.
C. Deviation handling. May lead to overfitting and underfitting. So you can consider discarding more data or supplementing less data. Consider existing data to synthesize some data. Depends on the impact on the results.

Data standardization.
For example, normalize the data to 0-1, etc.

Feature selection: Keep the data dimension as small as possible without reducing the effect of model training
The more dimensions there are, the more coefficients the data will shrink and the interpretability of the model will become worse. Reduced credibility
Too many dimensions cause slow operation, and too many dimensions may have a bad impact on the model.
For numerical data, you can use: principal component analysis method

Training set and test set:
a. Balance, direct random selection
b. Unbalanced: stratified sampling
How to build training and test sets:
a. Set aside method, directly divided into two parts without interfering with each other;
B. Cross-validation method: First divide the data set into N, use N-1 data sets for training each time, and use the rest as the test set. Carry out N times of training with this.
C. Bootstrapping method: When the data set is small, the data set is constructed through repeated sampling.
准备数据：如何处理出完整。干净的数据？

一. 要知道哪个项目需求要什么数据，并从哪里获取。即使公司存在数据部门，也要掌握数据库的使用技巧。如关系型数据库MuSQL，还要跟各种业务部门沟通协商以获取数据。

二。数据探索（把数据变多/数据升维）
数据变多：
a. 把内容进行分词，获得一个分词后的字段；
b. 把分此后的内容进行词语统计，看看哪个词出现的最多；
C。把标题进行分词，进行词语的统计
D。 可以对词语的词性进行标注，获得一份词性数据；
E。可以找一些特殊的词，比如名人的名字机构的名字。地点的名字等一些信息；如果是数值型数据，可以通过计算均值、方差、中位数、标准差、最大最小值去扩展。

三：数据清洗（把数据变少）
a. 缺失值处理。需要分析数据缺失的原因以及数据缺失的影响范围。一般是3中方式：删除、补全、忽视
B。异常值。错误情况/正常情况。处理办法为：错误数据-修正/丢弃；正确的-根据业务需求进行处理，按照异常情况进行保留/修正。
C。偏差处理。 可能导致过拟合和欠拟合。所以可以考虑丢弃较多或补充较少数据。考虑现有数据去合成一些数据。根据对结果的影响来定。

数据标准化。
比如把数据规范到0-1中，等

特征选择：尽可能留下较小的数据维度，而又可以不降低模型训练的效果
维度越多，数据就会约系数，模型的可解释性就会变差。可信度降低
过多维度造成运算的缓慢，同时过多的维度可能对模型产生不好影响。
对于数值型的数据可以使用：主成分分析方法

训练集和测试集：
a. 均衡性，直接随机抽取
b.非均衡：分层抽样
构建训练集和测试集的方法：
a. 留出法，直接划分为两个部分互不干扰；
B. 交叉验证法：先把数据集划分为N个，每次使用N-1个数据集训练，剩下的作为测试集。以此进行N次训练。
C。自助法：小数据集时，通过重复抽样构建数据集。

