假设数据共M条，计划分为3类

1. 先随机在一个数据空间中选取3个点，称之为中心点
2. 计算所有的点到这三个点的距离，这里的距离计算的是欧氏距离
3. 使用每个组的数据计算出这些数据的一个均值，使用这个均值作为下一轮迭代的中心点。
。。
重复上面的过程进行迭代
直到中心点的变动很小时，就可以停止运行了

面临的问题：
1. 如何面临K值（实际运用是也不知道有几个K）
方法：手肘法：循环尝试K值，计算在不同的K值情况下，所有数据的损失。即用每一个数据点到中心点的距离之和计算平均距离。当K为1时距离最大，当M时为0.所以在加大的过程中可以看到一个拐点，也即是手肘。
这个方法只适用于K值不太大的时候，如果K值几千几万，就要设置学习率大一些。
总体而言比较费时费力

优点：
简洁明了.计算复杂度低
收敛速度较快，迭代数次后效果一般较好

缺点：
结果不稳定
无法接近样本不均衡问题
容易收敛到局部最优解
受噪声影响较大 


衍生方法：

K-means++：在选取中心点时进行优化。
从已有的数据中随机的进行多次选取K个中心点，每次都计算这一次选中的中心点的距离，然后去一组最大的作为初始化中心点。

mini batch K-means: 改进了数据量/维度变大时运算缓慢的问题。在迭代时，每个集合中选取一部分进行计算，从而降低计算的复杂度。

总结：
聚类与分类的区别
K-means算法，非常简洁的基于划分的聚类算法
